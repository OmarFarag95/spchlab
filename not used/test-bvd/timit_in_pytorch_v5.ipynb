{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "timit_in_pytorch_v5",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-Sg0pH041mX"
      },
      "source": [
        "## Classification of Speech Frames\n",
        "\n",
        "### PART IV:  RECOGNIZE A PHONEME FROM FILTERBANK FEATURES WITH A DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEBOGxM441mY"
      },
      "source": [
        "### 1. Setting up your Python Environment\n",
        " \n",
        "1. Import Python's Machine Learning Stack\n",
        "\n",
        "2. Import needed local utilities that are needed for this exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "r-5Fz07p41mZ",
        "outputId": "3598a6b8-f230-4adc-8989-4303bad20299"
      },
      "source": [
        "% matplotlib inline\n",
        "import sys,os,io\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy.io as sio\n",
        "import urllib.request\n",
        "\n",
        "# imports from pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.manual_seed(0) # reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# imports from the scikit-learn \n",
        "from sklearn.datasets.base import Bunch\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn import metrics as skmetrics\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy.fftpack import dct\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  ! pip install git+https://github.com/compi1234/pyspch.git\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "from pyspch.GaussianMixtureClf import GaussianMixtureClf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/compi1234/spchlab.git\n",
            "  Cloning https://github.com/compi1234/spchlab.git to /tmp/pip-req-build-dl9jfjuv\n",
            "  Running command git clone -q https://github.com/compi1234/spchlab.git /tmp/pip-req-build-dl9jfjuv\n",
            "\u001b[31mERROR: File \"setup.py\" not found for legacy project git+https://github.com/compi1234/spchlab.git.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-89f0f0c5c9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mIN_COLAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspchutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianMixtureClf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixtureClf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spchutils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lVsE9SC5led",
        "cellView": "form"
      },
      "source": [
        "#@title Auxiliary functions \n",
        "\n",
        "## Pickle functions \n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "# save pickled file\n",
        "def pickle_data(df, filename):   \n",
        "    file_object = gzip.open(filename, \"wb\")\n",
        "    print(\"Generating \" + filename, end=\" ...\")\n",
        "    pickle.dump(df, file_object)\n",
        "    print(\"done\")\n",
        "    file_object.close()\n",
        "\n",
        "# open pickled file\n",
        "def unpickle_data(filename):\n",
        "    file_object = open(filename, \"rb\")\n",
        "    df = pickle.load(file_object)\n",
        "    file_object.close()\n",
        "    return df\n",
        "\n",
        "\n",
        "## Download functions\n",
        "\n",
        "import requests\n",
        "\n",
        "# download from url and write to file\n",
        "def write_from_url(url, filename):\n",
        "    r = requests.get(url)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "## Phoneme segmentation  \n",
        "\n",
        "# phone segmentation to phone per frame in utterance\n",
        "def phnseg_to_phns(phnseg, nframes):\n",
        "    phn_list = []\n",
        "    for seg_idx, seg in phnseg.iterrows():\n",
        "        seg_nframes = seg['t1'] - seg['t0']\n",
        "        phn_list += [seg['seg']] * seg_nframes\n",
        "        \n",
        "    return phn_list    \n",
        " \n",
        "# phone segmentation to center frame of phone per frame\n",
        "def phnseg_to_center_frames(phnseg, nframes):\n",
        "    center_frame_ids = []\n",
        "    for seg_idx, seg in phnseg.iterrows():\n",
        "        seg_nframes = seg['t1'] - seg['t0']\n",
        "        center_frame_ids += [int(seg['t0'] + seg_nframes / 2)] * seg_nframes\n",
        "        \n",
        "    return center_frame_ids\n",
        "\n",
        "\n",
        "##  Window\n",
        "\n",
        "# The window is determined by utterance boundaries (frame_idx, utt_nframes) \n",
        "# and the window parameters (window_nframes, stride). The window is represented \n",
        "# by indices relative to the frame index.\n",
        "\n",
        "# window indices relative to frame index\n",
        "def get_window(frame_idx, utt_nframes, window_nframes, stride, shift=0):\n",
        "    \n",
        "    def window_bounds(window_nframes):\n",
        "        if window_nframes % 2 == 0:    \n",
        "            # even case: start-i-center-i-i-end (example window_nframes=6)       \n",
        "            start = -window_nframes / 2 + 1\n",
        "            end = window_nframes / 2\n",
        "        else:                       \n",
        "            # uneven case: start-i-ref-i-stop (example window_nframes=5)       \n",
        "            start = -(window_nframes - 1) / 2\n",
        "            end = (window_nframes - 1) / 2  \n",
        "            \n",
        "        return start, end\n",
        "    \n",
        "    def adjust_window_to_utt_bounds(window):\n",
        "        new_window = []\n",
        "        for rel_idx in window:\n",
        "            rel_idx = max(rel_idx, 0 - frame_idx)\n",
        "            rel_idx = min(rel_idx, utt_nframes - 1 - frame_idx)\n",
        "            new_window.append(rel_idx)\n",
        "            \n",
        "        return np.array(new_window)\n",
        "    \n",
        "    # window boundaries w.r.t. center frame\n",
        "    start, end = window_bounds(window_nframes)\n",
        "    # window of evenly spaced frames around center frame\n",
        "    window = np.arange(start, end + 1).astype(int) \n",
        "    # apply stride and shift\n",
        "    window = window * stride + shift \n",
        "    # adjust window indices out of the utterance bounds\n",
        "    window = adjust_window_to_utt_bounds(window)\n",
        "    \n",
        "    return window\n",
        "\n",
        "# window indices for each frame in utterance\n",
        "def get_windows_for_utt(utt_nframes, window_nframes, stride, shift):\n",
        "    utt_windows = []\n",
        "    # iterate over frames in utterance\n",
        "    for frame_idx in range(utt_nframes):\n",
        "        window = get_window(frame_idx, utt_nframes,\n",
        "                            window_nframes, stride, shift)\n",
        "        utt_windows.append(window)\n",
        "    \n",
        "    return utt_windows\n",
        "\n",
        "# apply window to frames  \n",
        "def apply_window(frames, frame_ids, frame_windows):\n",
        "    inputs = []\n",
        "    # ensure type is numpy for easy indexing\n",
        "    frames = np.array(frames)\n",
        "    # iterate over frames \n",
        "    for frame_idx, frame_window in zip(frame_ids, frame_windows):\n",
        "        # apply window\n",
        "        feature = np.stack(frames[frame_window + int(frame_idx)], axis=0)\n",
        "        # save feature\n",
        "        inputs.append(feature)\n",
        "        \n",
        "    return np.stack(inputs, axis=0)\n",
        "\n",
        "## Reshape\n",
        "\n",
        "# reshape features assuming first dimension is 'examples'\n",
        "def reshape_features(frames, shape=(-1,)):\n",
        "    # n_examples = len(frames)\n",
        "    # new_shape = (n_examples, *shape)\n",
        "    \n",
        "    return [np.reshape(frame, shape) for frame in frames]\n",
        "\n",
        "## Normalization and derrivatives\n",
        "\n",
        "# normalization\n",
        "def normalize_data(data, axis=0, normMean=False, normVar=True):\n",
        "    if normMean:\n",
        "        mean = data.std(axis=axis) \n",
        "        data = np.subtract(data, mean)\n",
        "    if normVar:\n",
        "        stdev = data.std(axis=axis) \n",
        "        data = np.divide(data, stdev)\n",
        "    \n",
        "    return data\n",
        "\n",
        "# temporal derrivatives\n",
        "def add_derrivatives_data(data, delta=True, ddelta=True):   \n",
        "    if delta:\n",
        "        data_delta = np.gradient(data, axis=0)\n",
        "        data = np.concatenate((data, data_delta), axis=-1)\n",
        "    if ddelta:\n",
        "        data_delta = np.gradient(data, axis=0)\n",
        "        data_ddelta = np.gradient(data_delta, axis=0)\n",
        "        data = np.concatenate((data, data_delta, data_ddelta), axis=-1)\n",
        " \n",
        "    return data\n",
        "\n",
        "\n",
        "## Wrapper for assembling dataframe containing frames \n",
        "\n",
        "# assemble dataframe\n",
        "#   = row per frame\n",
        "# - path                    = utterance identifier\n",
        "# - center frame index      = index of center frame for current phoneme\n",
        "# - frame index             = index of frame for current phoneme\n",
        "# - window indices          = window indices \n",
        "def assemble_frame_dataframe(df, window_nframes=5, stride=2, shift=0,\n",
        "                             delta=True, ddelta=False,\n",
        "                             normMean=False, normVar=True):\n",
        "    frame_dfs = []\n",
        "    # iterate over utterances\n",
        "    for _, utt in df.iterrows():\n",
        "        \n",
        "        ## modify feature vector\n",
        "        # utterance data\n",
        "        data = utt['data']\n",
        "        # add temporal derrivatives\n",
        "        data = add_derrivatives_data(data, delta=delta, ddelta=ddelta)\n",
        "        # normalize standard deviation per channel (feature dimension)\n",
        "        data = normalize_data(data, axis=0, normMean=normMean, normVar=normVar)\n",
        "        \n",
        "        ## labels and names\n",
        "        # number of frames in utterance\n",
        "        utt_nframes = data.shape[0]\n",
        "        # utterance name for each frame\n",
        "        utt_names = [utt['utt_name']] * utt_nframes\n",
        "        # phone segmentation to phone per frame in utterance\n",
        "        phnseg = utt['phn_seg']\n",
        "        utt_phns = phnseg_to_phns(phnseg, utt_nframes)\n",
        "        centre_frame_ids = phnseg_to_center_frames(phnseg, utt_nframes)\n",
        "        # - indices of (feature) window per frame in utterance \n",
        "        utt_windows = get_windows_for_utt(utt_nframes, window_nframes=window_nframes, \n",
        "                                          stride=stride, shift=shift)\n",
        "        \n",
        "        # index of last frame\n",
        "        # - correct for occasional mismatch in number of frames and phone labels\n",
        "        eidx = min(utt_nframes, len(utt_phns))\n",
        "        \n",
        "        ## frame dataframe per utterance  \n",
        "        # - row per frame in utterance\n",
        "        # - columns: \"utt_name\", \"frame_idx\", window\", \"data\", \"phn_label\"\n",
        "        frame_df = pd.DataFrame({'utt_name' : utt_names[:eidx],\n",
        "                               'center_frame_idx' : centre_frame_ids[:eidx],\n",
        "                               'frame_idx' : np.arange(utt_nframes)[:eidx],\n",
        "                               'window' :  utt_windows[:eidx],\n",
        "                               'data' : list(data[:eidx]),\n",
        "                               'org_phn_label' : utt_phns[:eidx]})\n",
        "         \n",
        "        frame_dfs.append(frame_df)\n",
        "    \n",
        "    # concatenate frame dataframes per utterance to final frame dataframe \n",
        "    frame_df = pd.concat(frame_dfs, ignore_index=True)\n",
        "    \n",
        "    return frame_df\n",
        "\n",
        "\n",
        "## Phone and label mapping \n",
        "\n",
        "# TIMIT phone label to phone label (using phone_map_file)\n",
        "def get_phn2phn_map(phone_map_file, ocol, icol=0):\n",
        "    phn2phn = {}\n",
        "    with open(phone_map_file) as file:\n",
        "        for line in file:\n",
        "            w = line.strip().split(\"\\t\")\n",
        "            phn2phn[w[icol]] = w[ocol]\n",
        "            \n",
        "    return phn2phn \n",
        "\n",
        "# phone label to numeric label\n",
        "def get_phn2lab_map(phn_labels):\n",
        "    phn_labels = unique_list(phn_labels)\n",
        "    phn2lab_map = {phn : i for i, phn in enumerate(phn_labels) }\n",
        "    lab2phn_map = {i : phn for i, phn in enumerate(phn_labels) }\n",
        "    \n",
        "    return phn2lab_map, lab2phn_map \n",
        "\n",
        "# numeric label (based on 'icol') to other numeric label (based on '0col')\n",
        "def get_lab2lab_dict(phone_map_file, icol, ocol, phn_set=None):\n",
        "    # phn2phn\n",
        "    iphn2ophn = get_phn2phn_map(phone_map_file, ocol, icol)\n",
        "\n",
        "    # phn2lab x2\n",
        "    iphn2lab, _ = get_phn2lab_map(list(iphn2ophn.keys()))\n",
        "    ophn2lab, _ = get_phn2lab_map(list(iphn2ophn.values())) \n",
        "\n",
        "    # lab2lab\n",
        "    ilab2olab = {iphn2lab[k]:ophn2lab[v] for k,v in iphn2ophn.items()}\n",
        "    \n",
        "    return ilab2olab\n",
        "\n",
        "# get unique items in list\n",
        "def unique_list(lst): \n",
        "    # dict perserves order (vs. set)\n",
        "    return list(dict.fromkeys(lst))\n",
        "\n",
        "\n",
        "## Operations on dataframe  {display-mode: \"form\"}\n",
        "\n",
        "# split 'utt_name' column for easy data selection\n",
        "def split_string_column(df, col_dict, sep=\"/\"):  \n",
        "    for key, value in col_dict['target'].items():\n",
        "        df[key] = df.apply(lambda row: row[col_dict['source']].split(sep)[value], axis=1)\n",
        "    \n",
        "    return df \n",
        "\n",
        "# data selection based on regex in columns\n",
        "def filter_regex_dataframe(df, include, exclude=None):\n",
        "    if include is not None:\n",
        "        for key, value in include.items():\n",
        "            if value is not None:\n",
        "                df = df[df[key].str.contains(value)]\n",
        "                \n",
        "    if exclude is not None:\n",
        "        for key, value in exclude.items():\n",
        "            if value is not None:\n",
        "                df = df[~df[key].str.contains(value)]\n",
        "    \n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mkvnYsh4-kkR"
      },
      "source": [
        "#@title Wrapper functions\n",
        "def phone_and_label_mapping(phone_map_file, ocol=1, phn_set=None):\n",
        "\n",
        "    # phone mapping parameters\n",
        "    # ocol -> {0 : TIMIT 61 phone label, 1 : 48 phone label, 2: 39 phone label}\n",
        "\n",
        "    # phone mapping - phn2phn dictionairy = {TIMIT phone label : phone label}\n",
        "    phn2phn = get_phn2phn_map(phone_map_file, ocol=ocol)\n",
        "\n",
        "    # label mapping - phn2lab dictionairy = {phone label : integer label}\n",
        "    if phn_set == None:\n",
        "        phn_set = unique_list([phn for phn in phn2phn.values()]) # all values\n",
        "    \n",
        "    phn2lab, lab2phn = get_phn2lab_map(phn_set)\n",
        "\n",
        "    return phn2phn, phn2lab, lab2phn, phn_set\n",
        "\n",
        "# split in train / validation / test set \n",
        "def utterance_based_data_split(frames_df): \n",
        "\n",
        "    # add columns for easy splitting\n",
        "    col_dict = {'source' : 'utt_name',\n",
        "                'target' : {'dataset' : 0, 'dialect' : 1, \n",
        "                            'speaker' : 2, 'utterance' : 3}}\n",
        "    frames_df = split_string_column(frames_df, col_dict=col_dict, sep='/')\n",
        "\n",
        "    # define split\n",
        "    train_re_incl = {'dataset' : 'train'}\n",
        "    train_re_excl = {'dialect' : 'dr8', 'utterance' : 'sa'}\n",
        "    valid_re_incl = {'dataset' : 'train', 'dialect' : 'dr8'}\n",
        "    valid_re_excl = {'utterance' : 'sa'}\n",
        "    test_re_incl = {'dataset' : 'test'}\n",
        "    test_re_excl = {'utterance' : 'sa'}\n",
        "\n",
        "    # split\n",
        "    train_df = filter_regex_dataframe(frames_df, train_re_incl, train_re_excl)\n",
        "    valid_df = filter_regex_dataframe(frames_df, valid_re_incl, valid_re_excl)\n",
        "    test_df = filter_regex_dataframe(frames_df, test_re_incl, test_re_excl)\n",
        "\n",
        "    return train_df, valid_df, test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "q1Tqystd4sCz"
      },
      "source": [
        "#@title Pytorch functions\n",
        "\n",
        "## Neural network architecure\n",
        "\n",
        "# simple fully-connected feedforward neural network \n",
        "class Dnn(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim, hidden_layer_sizes):\n",
        "        super(Dnn, self).__init__()\n",
        "\n",
        "        # attributes\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "        # parameters\n",
        "        layer_sizes = (in_dim, *hidden_layer_sizes, out_dim)\n",
        "        layer_sizes_pairwise = [(layer_sizes[i], layer_sizes[i+1]) for \n",
        "                                 i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        # define architecture\n",
        "        modulelist = nn.ModuleList([])  \n",
        "        for i, (layer_in_size, layer_out_size) in enumerate(layer_sizes_pairwise):\n",
        "            modulelist.append(nn.Linear(layer_in_size, layer_out_size))\n",
        "            if i < len(self.hidden_layer_sizes):\n",
        "                modulelist.append(nn.Sigmoid())\n",
        "\n",
        "        # define network as nn.Sequential\n",
        "        self.net = nn.Sequential(*modulelist)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size = input.size(0)\n",
        "        shape = (batch_size, *self.shape)\n",
        "        out = input.view(shape)\n",
        "        return out\n",
        "\n",
        "\n",
        "# fully-connected neural network with 1D convolutional layer\n",
        "class Cnn1d(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim, hidden_layer_sizes,\n",
        "                 kernel_size=(5, ), padding=(2, ), n_filters=100,\n",
        "                 cnn_position=0):\n",
        "        super(Cnn1d, self).__init__()\n",
        "\n",
        "        # attributes\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "        # parameters\n",
        "        layer_sizes = (in_dim, *hidden_layer_sizes, out_dim)\n",
        "        layer_sizes_pairwise = [(layer_sizes[i], layer_sizes[i+1]) for \n",
        "                                 i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        # define architecture\n",
        "        modulelist = nn.ModuleList([])\n",
        "        for i, (layer_in_size, layer_out_size) in enumerate(layer_sizes_pairwise):\n",
        "\n",
        "            if i == cnn_position:\n",
        "                modulelist.append(nn.Conv1d(layer_in_size, n_filters, \n",
        "                                            kernel_size, padding=padding))\n",
        "                modulelist.append(View(shape=(-1, )))\n",
        "                    \n",
        "            else:\n",
        "                modulelist.append(nn.Linear(layer_in_size, layer_out_size))\n",
        "\n",
        "            if i < len(self.hidden_layer_sizes):\n",
        "                modulelist.append(nn.Sigmoid())\n",
        "\n",
        "        # define network as nn.Sequential\n",
        "        self.net = nn.Sequential(*modulelist)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "def init_weights(m, bias=0.00):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(bias)\n",
        "\n",
        "\n",
        "# fully-connected neural network with 1D convolutional layer\n",
        "class Cnn2d(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim, hidden_layer_sizes,\n",
        "                 kernel_size=(5, 5), padding=(2, 2), n_filters=25,\n",
        "                 cnn_position=0):\n",
        "        super(Cnn2d, self).__init__()\n",
        "\n",
        "        # attributes\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "        # parameters\n",
        "        layer_sizes = (in_dim, *hidden_layer_sizes, out_dim)\n",
        "        layer_sizes_pairwise = [(layer_sizes[i], layer_sizes[i+1]) for \n",
        "                                 i in range(len(layer_sizes)-1)]\n",
        "\n",
        "        # define architecture\n",
        "        modulelist = nn.ModuleList([])\n",
        "        for i, (layer_in_size, layer_out_size) in enumerate(layer_sizes_pairwise):\n",
        "\n",
        "            if i == cnn_position:\n",
        "                modulelist.append(nn.Conv2d(layer_in_size, n_filters, \n",
        "                                            kernel_size, padding=padding))\n",
        "                modulelist.append(View(shape=(-1, )))\n",
        "                    \n",
        "            else:\n",
        "                modulelist.append(nn.Linear(layer_in_size, layer_out_size))\n",
        "\n",
        "            if i < len(self.hidden_layer_sizes):\n",
        "                modulelist.append(nn.Sigmoid())\n",
        "\n",
        "        # define network as nn.Sequential\n",
        "        self.net = nn.Sequential(*modulelist)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Neural network training\n",
        "# =============================================================================\n",
        "\n",
        "# simple batch gradient descent \n",
        "def train_batch(network, train_X, train_y, criterion, optimizer, device, \n",
        "                n_epochs=500, every=10):\n",
        "\n",
        "    # data-format is torch tensor + send to device (ex. GPU)\n",
        "    if not torch.is_tensor(train_X):\n",
        "        train_X = torch.tensor(train_X, dtype=torch.float32).to(device)\n",
        "    if not torch.is_tensor(train_y):\n",
        "        train_y = torch.tensor(train_y, dtype=torch.long).to(device)\n",
        "\n",
        "    # send network to device (ex. GPU)\n",
        "    network.to(device)\n",
        "\n",
        "    # set network to training mode (vs. evaluation mode)\n",
        "    network.train() \n",
        "\n",
        "    # save training loss\n",
        "    train_loss = []\n",
        "\n",
        "    # train for some epochs - full batch\n",
        "    for epoch in range(n_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = network(train_X)\n",
        "        loss = criterion(output, train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch%every == 0:\n",
        "          print('Epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "      \n",
        "    return train_loss\n",
        "            \n",
        "# mini-batch gradient descent with early stopping\n",
        "def train(network, train_dl, criterion, optimizer, device, n_epochs=500, \n",
        "          valid_X=None, valid_y=None, patience=5, every=10, \n",
        "          current_epoch=0):\n",
        "\n",
        "    # set early stopping counter\n",
        "    cnt_valid_loss_increase = 0\n",
        "\n",
        "    # current_epoch\n",
        "    last_epoch = current_epoch\n",
        "\n",
        "    # data-format is torch tensor + send to device (ex. GPU)\n",
        "    if not torch.is_tensor(valid_X):\n",
        "        valid_X = torch.tensor(valid_X, dtype=torch.float32).to(device)\n",
        "    if not torch.is_tensor(valid_y):\n",
        "        valid_y = torch.tensor(valid_y, dtype=torch.long).to(device)\n",
        "\n",
        "    # save training and validation loss\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "\n",
        "    #  per epoch: update network parameters \n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # network to training mode\n",
        "        network.train()\n",
        "        \n",
        "        # early stopping \n",
        "        earlystoppping = cnt_valid_loss_increase > patience\n",
        "        if earlystoppping:\n",
        "            print(\"stopped early after %d epochs\" % (epoch))\n",
        "            return train_loss_list, valid_loss_list, last_epoch\n",
        "\n",
        "        # per mini-batch: compute gradient (backpropagation) + take step \n",
        "        running_loss = 0\n",
        "        steps = 0 \n",
        "        for i, data in enumerate(train_dl, 0):\n",
        "\n",
        "            # mini-batch inputs and labels\n",
        "            frames, labels = data  \n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward + backward + optimize \n",
        "            outputs = network.net(frames)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()  \n",
        "\n",
        "            # running loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # training loss\n",
        "        mean_minibatch_loss = running_loss/len(train_dl)\n",
        "        train_loss_list.append(mean_minibatch_loss)\n",
        "        if epoch%every == 0:   \n",
        "            print(\"Epoch %d -- av. loss per mini-batch %.2f\" % (epoch, mean_minibatch_loss))\n",
        "\n",
        "        # validation loss\n",
        "        if valid_X is not None and valid_y is not None: \n",
        "            # network to evaluation mode\n",
        "            network.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_outputs = network.net(valid_X)\n",
        "                valid_loss = criterion(valid_outputs, valid_y)\n",
        "                valid_loss_list.append(valid_loss.item())\n",
        "                \n",
        "                # early stoppping\n",
        "                loss_increase = valid_loss_list[-1] > min(valid_loss_list[-patience:])\n",
        "                if loss_increase:\n",
        "                    # no improvement compared to last 'patience' steps\n",
        "                    cnt_valid_loss_increase += 1\n",
        "                else:\n",
        "                    cnt_valid_loss_increase = 0\n",
        "\n",
        "        last_epoch = current_epoch + epoch + 1\n",
        "\n",
        "    return train_loss_list, valid_loss_list, last_epoch\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Neural network saving and loading \n",
        "# =============================================================================\n",
        "\n",
        "# save model\n",
        "def save_model(epoch, model, criterion, optimizer, model_file):\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'criterion': criterion,\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, model_file)\n",
        "    \n",
        "    doPrint = False\n",
        "    if doPrint:\n",
        "        print('Saved model to: ' + model_file)\n",
        "\n",
        "# load model\n",
        "def load_model(model, optimizer, model_file, device, strict=False):\n",
        "    doPrint = False\n",
        "    if doPrint:\n",
        "        print('Loading: ' + model_file)\n",
        "        \n",
        "    checkpoint = torch.load(model_file, map_location=device)\n",
        "    epoch = checkpoint['epoch']    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'], strict=strict)\n",
        "    criterion = checkpoint['criterion']\n",
        "    if doPrint:\n",
        "        print(checkpoint['optimizer_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    \n",
        "    return epoch, model, criterion, optimizer\n",
        "\n",
        "\n",
        "## Neural network evaluation\n",
        "\n",
        "# evaluate criterion\n",
        "def evaluate_criterion(network, test_X, test_y, criterion, device):\n",
        "    \n",
        "    # data-format is torch tensor + send to device (ex. GPU)\n",
        "    if not torch.is_tensor(test_X):\n",
        "        test_X = torch.tensor(test_X, dtype=torch.float32).to(device)\n",
        "    if not torch.is_tensor(test_y):\n",
        "        test_y = torch.tensor(test_y, dtype=torch.long).to(device)\n",
        "\n",
        "    # send network to device (ex. GPU)\n",
        "    network.to(device)\n",
        "\n",
        "    # set network to evaluation mode (vs. training mode)\n",
        "    network.eval() \n",
        "\n",
        "    # compute loss based on criterion\n",
        "    pred_y = network.net(test_X)\n",
        "    loss = criterion(pred_y, test_y)\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# evaluate confusion matrix\n",
        "def confusionmatrix(network, test_X, test_y, device, \n",
        "                    n_per_pass=2**10, unsqueeze=False, unsqueeze2d=False):\n",
        "    \n",
        "    # data-format is torch tensor + send to device (ex. GPU)\n",
        "    if not torch.is_tensor(test_X):\n",
        "        test_X = torch.tensor(test_X, dtype=torch.float32).to(device)\n",
        "    if not torch.is_tensor(test_y):\n",
        "        test_y = torch.tensor(test_y, dtype=torch.long).to(device)\n",
        "\n",
        "    # send network to device (ex. GPU)\n",
        "    network.to(device)\n",
        "\n",
        "    # set network to evaluation mode (vs. training mode)\n",
        "    network.eval() \n",
        "\n",
        "    # compute confusion matrix\n",
        "    cm = np.zeros((network.out_dim, network.out_dim))\n",
        "        \n",
        "    # splitting up dataframe in managable chunks\n",
        "    n_samples = len(test_X)\n",
        "    loop_n_times = math.ceil(n_samples/n_per_pass)\n",
        "    for i in range(loop_n_times):\n",
        "      test_X_part = test_X[i*n_per_pass:(i+1)*n_per_pass]\n",
        "      test_y_part = test_y[i*n_per_pass:(i+1)*n_per_pass]\n",
        "      for input, label in zip(test_X_part, test_y_part):\n",
        "        if unsqueeze: prob = network.net(torch.unsqueeze(input, 0))\n",
        "        elif unsqueeze2d: prob = network.net(torch.reshape(input, (1, *input.shape)))\n",
        "        else: prob = network.net(input) # output = posterior class probabilities\n",
        "        pred = torch.argmax(prob) # prediction = label (or neuron) with highest probability (One-Hot Encoding)\n",
        "        cm[label][pred] += 1\n",
        "    \n",
        "    return cm.astype(int)\n",
        "\n",
        "\n",
        "# remap confusion matrix\n",
        "def remap_confusionmatrix(confusionmatrix, lab2lab_dict):\n",
        "    \n",
        "    n_classes = confusionmatrix.shape[0]\n",
        "    n_classes_new = len(np.unique((np.fromiter(lab2lab_dict.values(), dtype=int))))\n",
        "    confusionmatrix_new = np.zeros((n_classes_new, n_classes_new))\n",
        "    \n",
        "    # remap classes\n",
        "    for row in range(n_classes):\n",
        "        for col in range(n_classes):\n",
        "            confusionmatrix_new[lab2lab_dict[row], lab2lab_dict[col]] += confusionmatrix[row,col]\n",
        "            \n",
        "    return confusionmatrix_new\n",
        "\n",
        "# evaluate phone error rate\n",
        "def evaluate_PER(confusionmatrix):\n",
        "\n",
        "    n_classes = confusionmatrix.shape[0]    \n",
        "    \n",
        "    # compute ER \n",
        "    trace = np.trace(confusionmatrix)\n",
        "    ER = 1- trace.sum() / confusionmatrix.sum()\n",
        "        \n",
        "    # compute ER per class (disregarding non label or not)\n",
        "    no_examples_pc = confusionmatrix.sum(axis=1)\n",
        "    ER_pc = [None] * n_classes\n",
        "    for i in range(n_classes):\n",
        "        if no_examples_pc[i] != 0:\n",
        "            ER_pc[i] = 1-confusionmatrix[i,i] / (no_examples_pc[i])\n",
        "        \n",
        "    return ER, ER_pc\n",
        "\n",
        "\n",
        "## Confusion matrix plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# pretty printing\n",
        "def plot_confusion_matrix(cm, labels=[], cmap=[], figsize=(6,6), fontsize=14):\n",
        "\n",
        "    if len(labels) == 0:\n",
        "        df_cm = pd.DataFrame(cm)\n",
        "    else:\n",
        "        df_cm = pd.DataFrame(cm, labels, labels)\n",
        "        \n",
        "    f, ax = plt.subplots(figsize=figsize)\n",
        "    sns.set(font_scale=1.4)#for label size\n",
        "    sns.heatmap(df_cm, annot=True, fmt=\"d\", annot_kws={\"fontsize\": fontsize,\"color\":'k'},\n",
        "                square=True, linecolor='k', linewidth=1.5, cmap=cmap, cbar=False)\n",
        "    ax.tick_params(axis='y', labelrotation=0.0, left=True)\n",
        "    # font size\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "## Dataset \n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    \"\"\"Simple dataset for easy sampling.\"\"\"\n",
        "\n",
        "    def __init__(self, data_X, data_y, labels, labeldict, device):\n",
        "\n",
        "        # dimensionality\n",
        "        self.n_samples, self.n_features = data_X.shape[0:2]\n",
        "        self.n_classes = len(labels)\n",
        "\n",
        "        # input data\n",
        "        self.frames = data_X # (n_samples, n_features)\n",
        "        self.frames = torch.as_tensor(self.frames, dtype=torch.float32).to(device)\n",
        "\n",
        "        # labels\n",
        "        if data_y.dtype != \"int64\":\n",
        "            data_y = np.vectorize(labeldict.get)(data_y)\n",
        "        self.labels = torch.as_tensor(data_y, dtype=torch.long).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame = self.frames[idx] \n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        return frame, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wqHgOBsz8qxq"
      },
      "source": [
        "#@title Define setups\n",
        "\n",
        "def prepare_baseline(utt_df, utt_names=None, phone_map_file='phones-61-48-39.txt'):\n",
        "    \n",
        "    ## DATA SELECTION -- utterance based (speed up)\n",
        "    if utt_names is not None:\n",
        "        utt_df = utt_df[utt_df['utt_name'].isin(utt_names)]\n",
        "\n",
        "    ## FEATURE EXTRACTION\n",
        "\n",
        "    # input feature parameters\n",
        "    window_nframes = 11\n",
        "    stride = 2\n",
        "    shift = 0\n",
        "    delta, ddelta = False, False\n",
        "    normMean, normVar = False, True\n",
        "\n",
        "    # generate dataframe containing frames\n",
        "    frames_df = assemble_frame_dataframe(utt_df, window_nframes, stride, shift, \\\n",
        "                                        delta, ddelta, normMean, normVar)\n",
        "\n",
        "    # assemble input feature from window\n",
        "    features = apply_window(frames_df['data'], frames_df.index, frames_df['window'])\n",
        "    #frames_df['feature'] = features\n",
        "    frames_df['feature'] = reshape_features(features, (-1,)) \n",
        "\n",
        "    ## LABELS\n",
        "\n",
        "    # phone and label mapping\n",
        "    ocol = 1 # {'61' : 0, '48' : 1, '39' : 2}\n",
        "    phn_set = None\n",
        "    phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)\n",
        "\n",
        "    # map phones and labels\n",
        "    frames_df['phn_label'] = frames_df['org_phn_label'].map(phn2phn) # TIMIT phone label -> phone label\n",
        "    frames_df['int_label'] = frames_df['phn_label'].map(phn2lab)  # phone label ->  integer label\n",
        "\n",
        "    ## DATA SELECTION -- frame based\n",
        "\n",
        "    # drop phones not in phn_set\n",
        "    frames_df = frames_df[~frames_df['int_label'].isna()] \n",
        "\n",
        "    # drop phones with large shift in phn_set\n",
        "    doShift = False\n",
        "    max_shift = 5 # shift = distance to center frame\n",
        "    if doShift:  \n",
        "      frames_df['shift'] = frames_df['frame_idx'] - frames_df['center_frame_idx']\n",
        "      frames_df = frames_df[frames_df['shift'].abs() < max_shift ]\n",
        "\n",
        "    return frames_df\n",
        "\n",
        "def prepare_shortvowels(utt_df, utt_names=None, phone_map_file='phones-61-48-39.txt',\n",
        "                        phn_set=['aa', 'ae', 'ah', 'ao', 'eh', 'ih', 'ix', 'uh']):\n",
        "    \n",
        "    ## DATA SELECTION -- utterance based (speed up)\n",
        "    if utt_names is not None:\n",
        "        utt_df = utt_df[utt_df['utt_name'].isin(utt_names)]\n",
        "\n",
        "    ## FEATURE EXTRACTION\n",
        "\n",
        "    # input feature parameters\n",
        "    window_nframes = 11\n",
        "    stride = 2\n",
        "    shift = 0\n",
        "    delta, ddelta = False, False\n",
        "    normMean, normVar = False, True\n",
        "\n",
        "    # generate dataframe containing frames\n",
        "    frames_df = assemble_frame_dataframe(utt_df, window_nframes, stride, shift, \\\n",
        "                                        delta, ddelta, normMean, normVar)\n",
        "\n",
        "    # assemble input feature from window\n",
        "    features = apply_window(frames_df['data'], frames_df.index, frames_df['window'])\n",
        "    frames_df['feature'] = reshape_features(features, (-1,)) \n",
        "\n",
        "    ## LABELS\n",
        "\n",
        "    # phone and label mapping\n",
        "    ocol = 1 # {'61' : 0, '48' : 1, '39' : 2}\n",
        "    #phn_set =  ['aa', 'ih']#['aa', 'ae', 'ah', 'ao', 'eh', 'ih', 'ix', 'uh'] \n",
        "    phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)\n",
        "\n",
        "    # map phones and labels\n",
        "    frames_df['phn_label'] = frames_df['org_phn_label'].map(phn2phn) # TIMIT phone label -> phone label\n",
        "    frames_df['int_label'] = frames_df['phn_label'].map(phn2lab)  # phone label ->  integer label\n",
        "\n",
        "    ## DATA SELECTION -- frame based\n",
        "\n",
        "    # drop phones not in phn_set\n",
        "    frames_df = frames_df[~frames_df['int_label'].isna()] \n",
        "\n",
        "    # drop phones with large shift in phn_set\n",
        "    doShift = False\n",
        "    max_shift = 5 # shift = distance to center frame\n",
        "    if doShift:  \n",
        "      frames_df['shift'] = frames_df['frame_idx'] - frames_df['center_frame_idx']\n",
        "      frames_df = frames_df[frames_df['shift'].abs() < max_shift ]\n",
        "\n",
        "    return frames_df\n",
        "\n",
        "def prepare_cnn(utt_df, utt_names=None, phone_map_file='phones-61-48-39.txt'):\n",
        "    \n",
        "    ## DATA SELECTION -- utterance based (speed up)\n",
        "    if utt_names is not None:\n",
        "        utt_df = utt_df[utt_df['utt_name'].isin(utt_names)]\n",
        "\n",
        "    ## FEATURE EXTRACTION\n",
        "\n",
        "    # input feature parameters\n",
        "    window_nframes = 11\n",
        "    stride = 2\n",
        "    shift = 0\n",
        "    delta, ddelta = False, False\n",
        "    normMean, normVar = False, True\n",
        "\n",
        "    # generate dataframe containing frames\n",
        "    frames_df = assemble_frame_dataframe(utt_df, window_nframes, stride, shift, \\\n",
        "                                        delta, ddelta, normMean, normVar)\n",
        "\n",
        "    # assemble input feature from window\n",
        "    features = apply_window(frames_df['data'], frames_df.index, frames_df['window'])\n",
        "    frames_df['feature'] = reshape_features(features, (-1,)) \n",
        "\n",
        "    ## LABELS\n",
        "\n",
        "    # phone and label mapping\n",
        "    ocol = 1 # {'61' : 0, '48' : 1, '39' : 2}\n",
        "    phn_set = None\n",
        "    phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)\n",
        "\n",
        "    # map phones and labels\n",
        "    frames_df['phn_label'] = frames_df['org_phn_label'].map(phn2phn) # TIMIT phone label -> phone label\n",
        "    frames_df['int_label'] = frames_df['phn_label'].map(phn2lab)  # phone label ->  integer label\n",
        "\n",
        "    ## DATA SELECTION -- frame based\n",
        "\n",
        "    # drop phones not in phn_set\n",
        "    frames_df = frames_df[~frames_df['int_label'].isna()] \n",
        "\n",
        "    # drop phones with large shift in phn_set\n",
        "    doShift = False\n",
        "    max_shift = 5 # shift = distance to center frame\n",
        "    if doShift:  \n",
        "      frames_df['shift'] = frames_df['frame_idx'] - frames_df['center_frame_idx']\n",
        "      frames_df = frames_df[frames_df['shift'].abs() < max_shift ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7CTQZHde3Q-",
        "cellView": "form"
      },
      "source": [
        "#@title Define setups\n",
        "\n",
        "f11s2_setup = {'window_nframes' : 11, 'stride' : 2, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f7s2_setup = {'window_nframes' : 7, 'stride' : 2, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f7s2d_setup = {'window_nframes' : 7, 'stride' : 1, 'shift' : 0,\n",
        "               'delta' : True, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f13s1_setup = {'window_nframes' : 13, 'stride' : 1, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f13s2_setup = {'window_nframes' : 13, 'stride' : 2, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "\n",
        "def prepare_setup(utt_df, setup, utt_names=None, ocol=1, phn_set=None,  \n",
        "                  phone_map_file='phones-61-48-39.txt'):\n",
        "    \n",
        "    ## DATA SELECTION -- utterance based (speed up)\n",
        "    if utt_names is not None:\n",
        "        utt_df = utt_df[utt_df['utt_name'].isin(utt_names)]\n",
        "\n",
        "    ## FEATURE EXTRACTION\n",
        "\n",
        "    # input feature parameters\n",
        "    window_nframes = setup['window_nframes']\n",
        "    stride = setup['stride']\n",
        "    shift = setup['shift']\n",
        "    delta, ddelta = setup['delta'], setup['ddelta']\n",
        "    normMean, normVar = setup['normMean'], setup['normVar']\n",
        "\n",
        "    # generate dataframe containing frames\n",
        "    frames_df = assemble_frame_dataframe(utt_df, window_nframes, stride, shift, \\\n",
        "                                        delta, ddelta, normMean, normVar)\n",
        "\n",
        "    # assemble input feature from window\n",
        "    features = apply_window(frames_df['data'], frames_df.index, frames_df['window'])\n",
        "    frames_df['feature'] = reshape_features(features, (-1,)) \n",
        "\n",
        "    ## LABELS\n",
        "\n",
        "    # phone and label mapping\n",
        "    phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)\n",
        "\n",
        "    # map phones and labels\n",
        "    frames_df['phn_label'] = frames_df['org_phn_label'].map(phn2phn) # TIMIT phone label -> phone label\n",
        "    frames_df['int_label'] = frames_df['phn_label'].map(phn2lab)  # phone label ->  integer label\n",
        "\n",
        "    ## DATA SELECTION -- frame based\n",
        "\n",
        "    # drop phones not in phn_set\n",
        "    frames_df = frames_df[~frames_df['int_label'].isna()] \n",
        "\n",
        "    # drop phones with large shift in phn_set\n",
        "    doShift = False\n",
        "    max_shift = 5 # shift = distance to center frame\n",
        "    if doShift:  \n",
        "      frames_df['shift'] = frames_df['frame_idx'] - frames_df['center_frame_idx']\n",
        "      frames_df = frames_df[frames_df['shift'].abs() < max_shift ]\n",
        "\n",
        "    return frames_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIjZCTLg41mf"
      },
      "source": [
        "### 2. The Database \n",
        "The experiments in this notebook use the TIMIT database.\n",
        "Instead of starting from raw speech, we already extracted features (24 filterbank energies) from the speech signal. The feature is obtained by applying the FFT transform (**window step** = 10ms, window size = 30ms, window = Hamming, ...) and mel scaling to the speech waveform (16kHz). Note the window step determines the frame duration (10ms).\n",
        "\n",
        "The dataframe contains for each utterance:\n",
        "- utt_name : utterance name\n",
        "- data : matrix of # frames in utterance x 24 mel-scaled filterbank energies \n",
        "- phn_seg : segmentation of utterance into phones\n",
        "\n",
        "The phone mapping is used translate the original 61 phone labels used by TIMIT to a smaller phone set, either with 48 (or 39) phone labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFGXk5A9cS1a"
      },
      "source": [
        "# Download dataframe \n",
        "root_url = 'http://homes.esat.kuleuven.be/~spchlab/data/timit/'\n",
        "utt_df_url = root_url + 'examples/timit-fb24-100Hz-text.pkl' \n",
        "utt_df = pd.read_pickle(utt_df_url) \n",
        "\n",
        "# Download phone mapping\n",
        "phone_map_file = 'phones-61-48-39.txt'\n",
        "phone_map_file_url = root_url + 'examples/phones-61-48-39.txt'\n",
        "write_from_url(phone_map_file_url, phone_map_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xQtSoiNvL32"
      },
      "source": [
        "# Visualize 24 filterbank energies for an utterance\n",
        "loc = 1\n",
        "print(utt_df['utt_name'].iloc[loc])\n",
        "print(utt_df['text'].iloc[loc][8:])\n",
        "spchd.PlotSpg(spgdata=utt_df['data'].iloc[loc].T, segspg=utt_df['phn_seg'].iloc[loc])\n",
        "\n",
        "# phone segmentation\n",
        "print(utt_df['phn_seg'].iloc[loc][1:9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2z9d8nTTahS"
      },
      "source": [
        "#### Set phone label mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJMClB4518wJ"
      },
      "source": [
        "# Preprocessing (short vowel dataset)\n",
        "long_vowels = ['aw', 'ay', 'er', 'ey', 'iy', 'ow', 'oy', 'uw']\n",
        "short_vowels = ['aa', 'ao', 'ae', 'ah', 'ax', 'eh', 'ih', 'ix', 'uh']\n",
        "\n",
        "# compute phone and label mapping\n",
        "ocol = 1 # {0 :'61 phones' : 0, 1 : '48 phones', 2 : '39 phones'}\n",
        "phn_set = None # short_vowels # long_vowels\n",
        "phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ezItDBC8y9"
      },
      "source": [
        "### Baseline setup\n",
        "We will use a simple neural network to classify the frames. In Pytorch, the network is constructed as a sequence of modules (the basic building blocks). Here we use a fully connected feed-forward network, with a sigmoid activation function following each hidden layer. The network is then defined by the input, output and hidden layer sizes. \n",
        "\n",
        "The input feature is a window of 11 frames (black) around the target frame (red). Notice we use a stride of 2, giving window that spans 210 ms. \n",
        "\n",
        "The phone labels are one-hot encoded, we thus have a neuron for each phone label in the output layer of the network. By applying the softmax function at the end of the network, we obtain phone probabilities as outputs. The predicted label is then the one with the highest probabilty. \n",
        "\n",
        "<img src=\"http://homes.esat.kuleuven.be/~spchlab/data/timit/dnn_setup_3.PNG\" width=\"750\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnR8AG31FEmT"
      },
      "source": [
        "First we define a neural network architecture, then we load in weights from a pretrained model with the TIMIT training data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIvv_IEfAGNz"
      },
      "source": [
        "# set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-_YIr26AECG"
      },
      "source": [
        "# define neural network\n",
        "in_dim = 11 * 24\n",
        "out_dim = 48 # len(phn_set)\n",
        "hidden_layer_sizes = [1024, 768, 512]\n",
        "dnn_model = Dnn(in_dim, out_dim, hidden_layer_sizes)\n",
        "dnn_model.to(device)\n",
        "print(dnn_model)\n",
        "\n",
        "# training parameters\n",
        "batch_size = 128\n",
        "shuffle = True\n",
        "lrn_rate = 0.001\n",
        "weight_decay = 0\n",
        "\n",
        "# initialize optimizer\n",
        "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=lrn_rate, weight_decay=weight_decay) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBks7KpoCgAN"
      },
      "source": [
        "# download model\n",
        "model_file = 'models/dnn_baseline_model.pt'\n",
        "model_url = root_url + model_file\n",
        "write_from_url(model_url, model_file)\n",
        "\n",
        "# load model\n",
        "epoch, dnn_model, criterion, optimizer = load_model(dnn_model, optimizer, model_file, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q60GbldSGFJn"
      },
      "source": [
        "The posterior probabilties are now visualized for one entire utterance below. Because the dataset (after feature extraction) is quite big, we avoid loading unnecessary data. Here we only do the feature extraction for a single utterance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmCyP425kdZa"
      },
      "source": [
        "f11s2_setup = {'window_nframes' : 11, 'stride' : 2, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtFlTtUUNKSH"
      },
      "source": [
        "# baseline feature extraction for single example utterance \n",
        "example_name = 'test/dr1/faks0/si2203'\n",
        "example_df = prepare_setup(utt_df, f11s2_setup, [example_name])\n",
        "example_X = np.vstack(example_df['feature']).astype('float32') # example_df['feature']\n",
        "example_X = torch.Tensor(example_X).to(device)\n",
        "\n",
        "# output for single example utterance \n",
        "example_yp = dnn_model(example_X) # log probs\n",
        "example_yp = torch.nn.Softmax(dim=1)(example_yp) # probs\n",
        "\n",
        "# plot input\n",
        "if False:\n",
        "  utt_fig, utt_ax = plt.subplots(figsize=(15, 10))\n",
        "  utt_ax.matshow(example_X.cpu().detach().numpy().T)\n",
        "  print(utt_df[utt_df['utt_name']==example_name]['text'].iloc[0])\n",
        "\n",
        "# plot output - posterior probabilities\n",
        "plot_df = pd.DataFrame(example_yp.cpu().detach().numpy())\n",
        "plot_df.columns = [lab2phn[col] for col in plot_df.columns]\n",
        "cols = plot_df.columns # choose phones to plot\n",
        "cols = ['sil', 'vcl'] + short_vowels # + long_vowels # \n",
        "plot_df[cols].plot(title=\"Predicted phone probabilties\", figsize=(15, 3), xlim=[0, len(example_df)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNcVHNG22mlJ"
      },
      "source": [
        "### Evaluate baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQtOjs-sZpzu"
      },
      "source": [
        "Now we evaluate the pretrained model on the whole TIMIT test set. First we compute the confusion matrix and then, using the confusion matrix, the phone error rate (PER) (= 1 - accuracy) and the PER per phone label. Notice that working with the whole dataset is slower."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv-J0HAMpXjV"
      },
      "source": [
        "# data split\n",
        "utt_train_df, utt_val_df, utt_test_df = utterance_based_data_split(utt_df)\n",
        "\n",
        "# test set feature extraction (all test sentences = takes about a minute)\n",
        "test_df = prepare_setup(utt_test_df, f11s2_setup)\n",
        "\n",
        "# test set \n",
        "test_X = np.vstack(test_df['feature']).astype('float32') \n",
        "test_y = test_df['int_label'].to_numpy().astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eceODJAweby7"
      },
      "source": [
        "# confusionmatrix and phone error rate (another minute or two)\n",
        "cm = confusionmatrix(dnn_model, test_X, test_y, device)\n",
        "print(evaluate_PER(cm))\n",
        "\n",
        "# 48 phone set to 39 phone set mapping (rescore)\n",
        "lab2lab = get_lab2lab_dict(phone_map_file, 1, 2)\n",
        "cm39 = remap_confusionmatrix(cm, lab2lab)\n",
        "print(evaluate_PER(cm39))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50zt5owrsNH6"
      },
      "source": [
        "# plot normalized confusion matrix\n",
        "plotCm = True\n",
        "if plotCm:\n",
        "    from sklearn.preprocessing import normalize\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    cm_image = ax.matshow(normalize(cm, axis=0, norm='l1'), interpolation='nearest')\n",
        "    fig.colorbar(cm_image, ax=ax)\n",
        "\n",
        "plotCmDetail = False\n",
        "if plotCmDetail:\n",
        "    # detail plot confusion matrix\n",
        "    plot_confusion_matrix(cm, phn_set, figsize=(20,20), fontsize=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbGPiN70Kt0"
      },
      "source": [
        "### DNN vs. GMM on short vowels\n",
        "\n",
        "Last exercise session on phoneme classification, we compared the performance of DNNs and GMMs. Near the end we remarked the toy problem was too small for meaningful conclusions. Here we compare the two models on a subset of TIMIT data, namely for the short vowels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICmsIbytyz3"
      },
      "source": [
        "# free up disk space\n",
        "#del baseline_df \n",
        "#del utt_test_df\n",
        "#del test_df "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhOYltapZNje"
      },
      "source": [
        "# subset of phone labels\n",
        "long_vowels = ['aw', 'ay', 'er', 'ey', 'iy', 'ow', 'oy', 'uw']\n",
        "short_vowels = ['aa', 'ao', 'ae', 'ah', 'ax', 'eh', 'ih', 'ix', 'uh']\n",
        "\n",
        "# use a subset of phones\n",
        "phn_set = short_vowels # short_vowels # long_vowels # None # \n",
        "\n",
        "# compute phone and label mapping\n",
        "ocol = 1 # {0 :'61 phones' : 0, 1 : '48 phones', 2 : '39 phones'}\n",
        "phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uUzllKNVPqE"
      },
      "source": [
        "#### Preprocessing / Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OznF20WIPoFv"
      },
      "source": [
        "# feature extraction for all utterances \n",
        "shortvowels_df = prepare_setup(utt_df, f11s2_setup, phn_set=phn_set)\n",
        "\n",
        "# phone and label mapping\n",
        "phn2phn, phn2lab, lab2phn, phn_set = phone_and_label_mapping(phone_map_file, ocol, phn_set)\n",
        "\n",
        "# split data\n",
        "train_df, valid_df, test_df = utterance_based_data_split(shortvowels_df)\n",
        "\n",
        "# labels\n",
        "train_y = train_df['int_label'].to_numpy().astype('int64') \n",
        "valid_y = valid_df['int_label'].to_numpy().astype('int64')\n",
        "test_y = test_df['int_label'].to_numpy().astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCHjN0ADVW_Q"
      },
      "source": [
        "#### DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr81qX4GWER4"
      },
      "source": [
        "# DNN features\n",
        "dnn_train_X = np.vstack(train_df['feature']).astype('float32') \n",
        "dnn_valid_X = np.vstack(valid_df['feature']).astype('float32') \n",
        "dnn_test_X = np.vstack(test_df['feature']).astype('float32') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK90ZP4dU7hD"
      },
      "source": [
        "## DNN model - identical to baseline (except for output layer)\n",
        "\n",
        "# define neural network\n",
        "in_dim = 11 * 24\n",
        "out_dim = len(phn_set)\n",
        "hidden_layer_sizes = [1024, 768, 512]\n",
        "\n",
        "dnn_model = Dnn(in_dim, out_dim, hidden_layer_sizes)\n",
        "dnn_model.to(device)\n",
        "\n",
        "# training parameters\n",
        "n_epochs = 500\n",
        "patience = 15\n",
        "lrn_rate = 0.00001\n",
        "weight_decay = 0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # applies softmax()\n",
        "dnn_optimizer = torch.optim.Adam(dnn_model.parameters(), lr=lrn_rate, weight_decay=weight_decay)\n",
        "\n",
        "# dataset \n",
        "dnn_train_ds = SimpleDataset(dnn_train_X, train_y, phn_set, phn2lab, device)\n",
        "\n",
        "# dataloader\n",
        "batch_size = 128\n",
        "shuffle = True\n",
        "dnn_train_dl = DataLoader(dnn_train_ds, batch_size=batch_size, shuffle=shuffle, num_workers=0)\n",
        "\n",
        "# training\n",
        "dnn_results = train(dnn_model, dnn_train_dl, criterion, dnn_optimizer, device, \n",
        "                    n_epochs, dnn_valid_X, valid_y, patience, every=10)\n",
        "dnn_train_loss, dnn_valid_loss, dnn_epoch = dnn_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdvycGSeVMQ1"
      },
      "source": [
        "# plot training and validation loss\n",
        "plt.figure()\n",
        "plt.plot(dnn_train_loss)\n",
        "plt.plot(dnn_valid_loss)\n",
        "plt.title(\"Training and validation loss - fully connected input layer\")\n",
        "plt.legend(['train', 'validation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4wqmcCpVMQ8"
      },
      "source": [
        "# compute confusionmatrix \n",
        "dnn_cm = confusionmatrix(dnn_model, dnn_test_X, test_y, device)\n",
        "\n",
        "# phone error rate\n",
        "print(evaluate_PER(dnn_cm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3VOCkzVMQ8"
      },
      "source": [
        "# plot normalized confusion matrix\n",
        "plotCm = True\n",
        "if plotCm:\n",
        "    from sklearn.preprocessing import normalize\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    cm_image = ax.matshow(normalize(dnn_cm, axis=0, norm='l1'), interpolation='nearest')\n",
        "    fig.colorbar(cm_image, ax=ax)\n",
        "    ax.set_xticklabels(['']+list(phn2lab.keys()))  \n",
        "    ax.set_yticklabels(['']+list(phn2lab.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juY9JxdJgXvu"
      },
      "source": [
        "# save model\n",
        "!mkdir -p 'models/'\n",
        "dnn_model_file = 'models/dnn_shortvowel_model.pt'\n",
        "dnn_model_dict = {'epoch': dnn_epoch,\n",
        "                  'model_state_dict': dnn_model.state_dict(),\n",
        "                  'criterion': criterion,\n",
        "                  'optimizer_state_dict': dnn_optimizer.state_dict()}\n",
        "torch.save(dnn_model_dict, dnn_model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3UwpkkosV2D"
      },
      "source": [
        "#### GMM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gIiegoHbbCFL"
      },
      "source": [
        "#@title GMM functions\n",
        "\n",
        "# =============================================================================\n",
        "# GMM\n",
        "# =============================================================================\n",
        "\n",
        "def train_test_GMM(X_train,X_test,y_train,y_test,classes,\n",
        "                     n_components=1,max_iter=20,tol=1.e-3,print_result=True,print_cmat=False):\n",
        "    clf_GM = GaussianMixtureClf(classes=classes,n_components=n_components,max_iter=20,tol=1.e-3)\n",
        "    clf_GM.fit(X_train,y_train)\n",
        "    y_pred = clf_GM.predict(X_train)\n",
        "    acc_train = 100.0*skmetrics.accuracy_score(y_train, y_pred)\n",
        "    y_pred = clf_GM.predict(X_test)\n",
        "    acc_test = 100.0*skmetrics.accuracy_score(y_test, y_pred) \n",
        "    cmat = skmetrics.confusion_matrix(y_test,y_pred)\n",
        "    if(print_result):\n",
        "        lls, bics = llscore(clf_GM,X_train,y_train)\n",
        "        print('Training Set:  Accuracy = %.2f%%     LL = %.2f    BIC = %.2f ' % (acc_train,lls,bics) )\n",
        "        print('Test Set:      Accuracy = %.2f%%'  % (acc_test) )\n",
        "    if(print_cmat):\n",
        "        plot_confusion_matrix(cmat,labels=classes)\n",
        "    return (acc_test,acc_train)\n",
        "\n",
        "def llscore(GMM,X,y):\n",
        "    ''' Average log likelihood per sample over the full data set (X,y) \n",
        "    and BIC per sample '''\n",
        "    ll = 0.\n",
        "    for k in range(0,GMM.n_classes) :\n",
        "        ll += GMM.gmm[k].score(X[y== GMM.classes[k],: ])\n",
        "    lls = ll.mean()\n",
        "    nparam = ((2*n_dim+1)*n_components -1 ) * GMM.n_classes\n",
        "    bics = -2*lls + (np.log(X.shape[0])* nparam) / float(X.shape[0])\n",
        "    return(lls,bics)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzVZwjE6V_rp"
      },
      "source": [
        "# GMM features\n",
        "gmm_train_X = np.vstack(train_df['data']).astype('float32') \n",
        "gmm_valid_X = np.vstack(valid_df['data']).astype('float32') \n",
        "gmm_test_X = np.vstack(test_df['data']).astype('float32') \n",
        "\n",
        "# use MFCC features for GMM\n",
        "mfcc_train_X = dct(gmm_train_X, type=2, axis=1, norm='ortho')\n",
        "mfcc_test_X = dct(gmm_test_X, type=2, axis=1, norm='ortho')\n",
        "\n",
        "# add first order temporal derrivatives for GMM\n",
        "mfcc_train_X = add_derrivatives_data(mfcc_train_X, delta=True, ddelta=False)\n",
        "mfcc_test_X = add_derrivatives_data(mfcc_test_X, delta=True, ddelta=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7yZTd_lM7eK"
      },
      "source": [
        "# initialize model\n",
        "gmm_model = GaussianMixture(n_components=len(phn_set), covariance_type='diag', tol=0.001,\n",
        "                            reg_covar=1e-06, max_iter=100, n_init=1, \n",
        "                            init_params='kmeans', random_state=1, warm_start=False)\n",
        "\n",
        "# spchlab implementation \n",
        "if False:\n",
        "  gmm = GMM(n_components=len(phn_set), covariance_type='diag', tol=0.001, \n",
        "            min_covar=0.001, max_iter=100, n_init=1, init_params='kmeans', random_state=1)\n",
        "\n",
        "# train model\n",
        "gmm_model = gmm_model.fit(mfcc_train_X, train_y)\n",
        "\n",
        "# prediction and accuracy\n",
        "pred = gmm_model.predict(mfcc_test_X)\n",
        "count_correct = sum([1 for pr, lab in zip(pred, test_y) if pr==lab])\n",
        "per = 1 - count_correct/len(test_y)   \n",
        "print(per)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvTHGR-t458Q"
      },
      "source": [
        "# plot normalized confusion matrix\n",
        "plotCm = True\n",
        "if plotCm:\n",
        "    from sklearn.preprocessing import normalize\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    cm_image = ax.matshow(normalize(cm_shortvowels, axis=0, norm='l1'), interpolation='nearest')\n",
        "    fig.colorbar(cm_image, ax=ax)\n",
        "    ax.set_xticklabels(['']+list(phn2lab.keys()))  \n",
        "    ax.set_yticklabels(['']+list(phn2lab.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWAzcb7HXsGb"
      },
      "source": [
        "### DNN performance for different input features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5q1_inkkHv"
      },
      "source": [
        "f7s2_setup = {'window_nframes' : 7, 'stride' : 2, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f7s2d_setup = {'window_nframes' : 7, 'stride' : 1, 'shift' : 0,\n",
        "               'delta' : True, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f13s1_setup = {'window_nframes' : 13, 'stride' : 1, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}\n",
        "\n",
        "f13s2_setup = {'window_nframes' : 13, 'stride' : 2, 'shift' : 0,\n",
        "               'delta' : False, 'ddelta' : False,\n",
        "               'normMean' : False, 'normVar' : True}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSlTGLzpYTae"
      },
      "source": [
        "# download pretrained models\n",
        "model_files = ['models/dnn_f7s2_model.pt',     # 7 frames, stride 2 (130 ms)\n",
        "               'models/dnn_f7s2d_model.pt',    # 7 frames, stride 2, delta (130 ms)\n",
        "               'models/dnn_f13s1_model.pt',    # 13 frames, stride 1 (130 ms)\n",
        "               'models/dnn_f13s2_model.pt']    # 13 frames, stride 2 (250 ms)\n",
        "\n",
        "for model_file in model_files:\n",
        "  model_url = root_url + model_file\n",
        "  write_from_url(model_url, model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNHqOxbldQC3"
      },
      "source": [
        "setups = [f7s2_setup, f7s2d_setup, f13s1_setup, f13s2_setup]\n",
        "\n",
        "for model_file, setup in zip(model_files, setups): \n",
        "  \n",
        "  # define neural network\n",
        "  in_dim = 24 * setup['window_nframes'] * (1 + setup['delta'] + setup['ddelta'])\n",
        "  out_dim = 48\n",
        "  hidden_layer_sizes = [1024, 768, 512]\n",
        "\n",
        "  dnn_model = Dnn(in_dim, out_dim, hidden_layer_sizes)\n",
        "  dnn_model.to(device)\n",
        "\n",
        "  # optimizer parameters\n",
        "  lrn_rate = 0.00001\n",
        "  weight_decay = 0\n",
        "  optimizer = torch.optim.Adam(dnn_model.parameters(), lr=lrn_rate, weight_decay=weight_decay)\n",
        "  \n",
        "  # load model\n",
        "  epoch, dnn_model, criterion, optimizer = load_model(dnn_model, optimizer, model_file, device)\n",
        "\n",
        "  # baseline feature extraction for single example utterance \n",
        "  example_name = 'test/dr1/faks0/si2203'\n",
        "  example_df = prepare_setup(utt_df, setup, [example_name])\n",
        "  example_X = np.vstack(example_df['feature']).astype('float32') # example_df['feature']\n",
        "  example_X = torch.Tensor(example_X).to(device)\n",
        "\n",
        "  # output for single example utterance \n",
        "  example_yp = dnn_model(example_X) # log probs\n",
        "  example_yp = torch.nn.Softmax(dim=1)(example_yp) # probs\n",
        "\n",
        "  # plot input\n",
        "  if False:\n",
        "    utt_fig, utt_ax = plt.subplots(figsize=(15, 10))\n",
        "    utt_ax.matshow(example_X.cpu().detach().numpy().T)\n",
        "    print(utt_df[utt_df['utt_name']==example_name]['text'].iloc[0])\n",
        "\n",
        "  # plot output - posterior probabilities\n",
        "  plot_df = pd.DataFrame(example_yp.cpu().detach().numpy())\n",
        "  plot_df.columns = [lab2phn[col] for col in plot_df.columns]\n",
        "  cols = plot_df.columns # choose phones to plot\n",
        "  cols = ['sil', 'vcl'] + short_vowels # + long_vowels # \n",
        "  plot_df[cols].plot(title=\"Predicted phone probabilties\", figsize=(15, 3), xlim=[0, len(example_df)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4zm4MVxkEyJ"
      },
      "source": [
        "## KLAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C-dcKw50isO"
      },
      "source": [
        "### 4. Train a custom DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTIE5l75zO-i"
      },
      "source": [
        "# Train model \n",
        "\n",
        "# training setup\n",
        "n_epochs = 500\n",
        "patience = 5\n",
        "lrn_rate = 0.001\n",
        "weight_decay = 0\n",
        "nesterov = False\n",
        "criterion = nn.CrossEntropyLoss()  # applies softmax()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=lrn_rate, weight_decay=weight_decay, nesterov=nesterov)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lrn_rate, weight_decay=weight_decay) # ties model-parameters to optimizer (back-propagation)\n",
        "\n",
        "# train network\n",
        "mode = 'mb_es'\n",
        "every = 5\n",
        "if mode == 'batch': \n",
        "    train_loss = train_batch(model, train_dnn_X, train_y, criterion, optimizer, device, n_epochs, every)\n",
        "\n",
        "if mode == 'mb': \n",
        "    train_loss = train_minibatch(model, train_dl, criterion, optimizer, device, n_epochs, every)\n",
        "\n",
        "if mode == 'mb_es' : \n",
        "    train_loss, valid_loss = train_minibatch_earlystopping(model, train_dl, criterion, optimizer, device, n_epochs,\\\n",
        "                                                           valid_dnn_X, valid_y, patience, every)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8S49bCJZg-"
      },
      "source": [
        "### 3. Feature Extraction\n",
        "\n",
        "\n",
        "Q1. What happens to the input feature on the phone boundaries?\n",
        "\n",
        "Q2. What happens to the input feature on the utterance boundaries?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Ar-ZQiFRtH"
      },
      "source": [
        "Apart from segmenting the utterance in phones and computing the window for each input feature, we can also normalize and add temporal derrivatives to our feature. Here we will normalize the variance per channel (and per utterance) and add a first order temporal derrivative (called delta).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C53tOmp_VxRs"
      },
      "source": [
        "For each utterance the temporal derrivate is computed and the variance normalized per channel. The phone segmentation is translated to a phone for each frame and finally the window is computed. The code for this "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg18I2K9W1ck"
      },
      "source": [
        "### 4. Phone and Label Mapping \n",
        "The TIMIT phone labels are mapped onto a smaller set of 49 phones. If you want to run small experiments yourself, you can select a subset with only a couple of phonemes (reducing the size of the dataset and the diversity in labels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST5v8bTfX0Tj"
      },
      "source": [
        "We will use a simple feed forward neural network to classify the frames. In pytorch, the network is constructed as a sequence of modules (basic blocks). We have a fully connected network (nn.Linear), with the activation function (Sigmoid) between all layers. The network is then defined by the input-, output- and hidden layer sizes."
      ]
    }
  ]
}
